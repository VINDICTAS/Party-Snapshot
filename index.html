<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>AR Picture-Taking</title>
  <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
  <style>
    /* Styles for the "Take Snapshot" button */
    #capture-button {
      position: fixed;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      background-color: #ff5722;
      color: white;
      border: none;
      padding: 10px 20px;
      font-size: 16px;
      border-radius: 5px;
      cursor: pointer;
      z-index: 10; /* Ensure the button is above the AR session */
      display: none; /* Initially hidden */
    }

    /* Snapshot overlay (hidden by default) */
    #snapshot {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      display: none;
      justify-content: center;
      align-items: center;
      z-index: 10; /* On top of the AR content */
    }

    #snapshot img {
      max-width: 80%;
      max-height: 80%;
      border-radius: 10px;
    }

    #snapshot button {
      position: absolute;
      top: 10px;
      right: 10px;
      background-color: #f44336;
      color: white;
      border: none;
      padding: 10px 20px;
      font-size: 14px;
      border-radius: 5px;
      cursor: pointer;
    }
  </style>
</head>
<body>

<button id="start-button">Start WebXR AR</button>
<button id="capture-button">Take Snapshot</button>

<div id="snapshot">
  <img id="snapshot-image" src="" alt="Snapshot">
  <button id="close-snapshot">Close Snapshot</button>
</div>

<script>
  let mixers = [];
  let clock = new THREE.Clock();
  let renderer, scene, camera;

  async function activateXR() {
    try {
      // Hide the start button and show the capture button
      document.getElementById('start-button').style.display = 'none';
      document.getElementById('capture-button').style.display = 'block';

      // Setup renderer, scene, and camera
      const canvas = document.createElement("canvas");
      document.body.appendChild(canvas);
      const gl = canvas.getContext("webgl", { xrCompatible: true });
      renderer = new THREE.WebGLRenderer({ alpha: true, canvas: canvas, context: gl, preserveDrawingBuffer: true });
      renderer.autoClear = false;

      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;

      // Add lighting
      const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
      scene.add(ambientLight);

      const directionalLight = new THREE.DirectionalLight(0xffffff, 0.6);
      directionalLight.position.set(1, 1, 1).normalize();
      scene.add(directionalLight);

      // Load character with animation
      const loader = new THREE.GLTFLoader();
      const modelUrl = 'https://raw.githubusercontent.com/VINDICTAS/webxr-test/main/Fetard.glb';
      loader.load(modelUrl, (gltf) => {
        const model = gltf.scene;
        model.scale.set(0.3, 0.3, 0.3);
        model.position.set(0, -1.5, -2);
        scene.add(model);

        if (gltf.animations.length > 0) {
          const mixer = new THREE.AnimationMixer(model);
          const action = mixer.clipAction(gltf.animations[0]);
          action.play();
          mixers.push(mixer);

          // Store the mixer and gltf for future animation changes
          model.userData.mixer = mixer;
          model.userData.animations = gltf.animations;
        }
      });

      // Start WebXR session
      const session = await navigator.xr.requestSession("immersive-ar");
      session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });
      const referenceSpace = await session.requestReferenceSpace('local');

      let onXRFrame = (time, frame) => {
        session.requestAnimationFrame(onXRFrame);

        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);

        const pose = frame.getViewerPose(referenceSpace);
        if (pose) {
          const view = pose.views[0];
          const viewport = session.renderState.baseLayer.getViewport(view);
          renderer.setSize(viewport.width, viewport.height);

          camera.matrix.fromArray(view.transform.matrix);
          camera.projectionMatrix.fromArray(view.projectionMatrix);
          camera.updateMatrixWorld(true);

          const delta = clock.getDelta();
          mixers.forEach((mixer) => mixer.update(delta));

          renderer.render(scene, camera);
        }
      };

      session.requestAnimationFrame(onXRFrame);
    } catch (e) {
      console.error("Failed to start AR session", e);
    }
  }

  function takeSnapshot() {
    // Render the current AR scene to a snapshot canvas
    renderer.render(scene, camera);

    // Create a temporary canvas and draw the scene onto it
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = renderer.domElement.width;
    tempCanvas.height = renderer.domElement.height;
    const tempContext = tempCanvas.getContext('2d');
    tempContext.drawImage(renderer.domElement, 0, 0);

    // Create an image from the snapshot
    const snapshotImage = document.getElementById('snapshot-image');
    snapshotImage.src = tempCanvas.toDataURL('image/png');

    // Show the snapshot in the session (overlay)
    document.getElementById('snapshot').style.display = 'flex';
  }

  // Attach event listeners
  document.getElementById('start-button').addEventListener('click', activateXR);
  document.getElementById('capture-button').addEventListener('click', takeSnapshot);
  document.getElementById('close-snapshot').addEventListener('click', () => {
    document.getElementById('snapshot').style.display = 'none';
  });

</script>

</body>
</html>
