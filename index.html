<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>AR Test</title>

  <!-- three.js -->
  <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
  
  <style>
    #snapshotButton {
      position: absolute;
      top: 10px;
      right: 10px;
      padding: 10px 20px;
      background-color: rgba(255, 255, 255, 0.8);
      border: none;
      border-radius: 5px;
      cursor: pointer;
      z-index: 1000;
    }

    #snapshotPreview {
      position: absolute;
      bottom: 10px;
      right: 10px;
      width: 200px;
      height: auto;
      border: 2px solid #fff;
      z-index: 1000;
    }
  </style>
</head>
<body>

<button onclick="activateXR()">Start WebXR AR</button>
<button id="snapshotButton" style="display: none;" onclick="takeSnapshot()">Take Snapshot</button>
<img id="snapshotPreview" style="display: none;" />

<script>
  let mixers = []; // Array to store animation mixers for all characters
  let clock = new THREE.Clock();
  let renderer;

  async function activateXR() {
    try {
      // Cleanup previous instances
      const existingCanvas = document.querySelector("canvas");
      if (existingCanvas) {
        existingCanvas.remove();
      }

      // Reinitialize objects
      const canvas = document.createElement("canvas");
      document.body.appendChild(canvas);
      const gl = canvas.getContext("webgl", {xrCompatible: true});

      const scene = new THREE.Scene();

      // Add lighting
      const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
      scene.add(ambientLight);

      const directionalLight = new THREE.DirectionalLight(0xffffff, 0.6);
      directionalLight.position.set(1, 1, 1).normalize();
      scene.add(directionalLight);

      // Function to load models and animations
      async function loadCharacter(modelUrl, position, scale) {
        const loader = new THREE.GLTFLoader();
        return new Promise((resolve, reject) => {
          loader.load(
            modelUrl,
            (gltf) => {
              const model = gltf.scene;

              // Set position and scale
              model.position.set(...position);
              model.scale.set(...scale);
              scene.add(model);

              // Fix material transparency
              gltf.scene.traverse((child) => {
                if (child.isMesh) {
                  child.material.transparent = false;
                  child.material.opacity = 1.0;
                  child.renderOrder = 1;
                  child.material.needsUpdate = true;
                }
              });

              // Handle animations
              if (gltf.animations && gltf.animations.length > 0) {
                const mixer = new THREE.AnimationMixer(model);
                const action = mixer.clipAction(gltf.animations[0]);
                action.play();
                mixers.push(mixer); // Add mixer to the array
              }

              resolve(model);
            },
            undefined,
            (error) => {
              console.error('An error occurred while loading the model:', error);
              reject(error);
            }
          );
        });
      }

      // Load multiple characters
      await loadCharacter('https://raw.githubusercontent.com/VINDICTAS/webxr-test/main/Fetard.glb', [0, -1.5, -2], [0.4, 0.4, 0.4]);
      await loadCharacter('https://raw.githubusercontent.com/VINDICTAS/webxr-test/main/Guitariste.glb', [1, -1.5, -3], [0.4, 0.4, 0.4]);

      // Set up the renderer
      renderer = new THREE.WebGLRenderer({
        alpha: true,
        preserveDrawingBuffer: true, // Enable preserving the drawing buffer for snapshots
        canvas: canvas,
        context: gl,
      });
      renderer.autoClear = false;

      // Create the camera
      const camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;

      // Start the WebXR session
      const session = await navigator.xr.requestSession("immersive-ar");
      session.updateRenderState({
        baseLayer: new XRWebGLLayer(session, gl),
      });

      // Set up reference space
      const referenceSpace = await session.requestReferenceSpace('local');

      // Show the snapshot button
      document.getElementById('snapshotButton').style.display = 'block';

      // Render loop
      const onXRFrame = (time, frame) => {
        session.requestAnimationFrame(onXRFrame);

        // Bind framebuffer
        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);

        // Get device pose
        const pose = frame.getViewerPose(referenceSpace);
        if (pose) {
          const view = pose.views[0];
          const viewport = session.renderState.baseLayer.getViewport(view);
          renderer.setSize(viewport.width, viewport.height);

          // Update the camera matrices
          camera.matrix.fromArray(view.transform.matrix);
          camera.projectionMatrix.fromArray(view.projectionMatrix);
          camera.updateMatrixWorld(true);

          // Update animations for all mixers
          const delta = clock.getDelta();
          mixers.forEach((mixer) => mixer.update(delta));

          // Render the scene
          renderer.render(scene, camera);
        }
      };

      session.requestAnimationFrame(onXRFrame);
    } catch (e) {
      console.error("Failed to start AR session", e);
    }
  }

  function takeSnapshot() {
    const canvas = document.querySelector("canvas");
    const snapshot = canvas.toDataURL("image/png");
    const snapshotPreview = document.getElementById("snapshotPreview");
    snapshotPreview.src = snapshot;
    snapshotPreview.style.display = 'block';
  }
</script>

</body>
</html>
