<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>AR Test</title>

  <!-- three.js -->
  <script src="https://cdn.jsdelivr.net/npm/three@latest/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@latest/examples/js/loaders/GLTFLoader.js"></script>
</head>
<body>

<button onclick="activateXR()">Start WebXR AR</button>
<script>
  let compassHeading = 0; // Global variable to store the heading

  // Listen for device orientation changes
  window.addEventListener("deviceorientationabsolute", (event) => {
      if (event.alpha !== null) {
          compassHeading = THREE.MathUtils.degToRad(event.alpha); // Convert degrees to radians
      } else {
          console.warn("Device orientation not supported or not granted permission.");
      }
  });

  async function activateXR() {
    try {
      const canvas = document.createElement("canvas");
      document.body.appendChild(canvas);
      const gl = canvas.getContext("webgl", {xrCompatible: true});

      const scene = new THREE.Scene();

      // Add lighting to illuminate the models
      const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
      scene.add(ambientLight);

      // Increase the intensity of the directional light
      const directionalLight = new THREE.DirectionalLight(0xffffff, 1.0); // 1.0 intensity
      directionalLight.position.set(1, 2, 1).normalize();
      scene.add(directionalLight);

      // Optionally, add a second light to ensure uniform illumination
      const additionalLight = new THREE.PointLight(0xffffff, 1.5); // Higher intensity
      additionalLight.position.set(0, 2, -2);
      scene.add(additionalLight);


      // Load the GLTF model
      const loader = new THREE.GLTFLoader();
      const modelUrl = 'https://raw.githubusercontent.com/VINDICTAS/webxr-test/main/Base3.glb';
      let mixer; // Declare the mixer for animations
      loader.load(modelUrl, (gltf) => {
        const model = gltf.scene;

        // Adjust the size and position of the model
        model.scale.set(0.3, 0.3, 0.3);
        model.position.set(0, -1, -1); // Adjust the position as needed
        scene.add(model);
        

        // Check if the model has animations
        if (gltf.animations && gltf.animations.length > 0) {
          mixer = new THREE.AnimationMixer(model);
          const action = mixer.clipAction(gltf.animations[0]);
          action.play();
        }
      }, undefined, (error) => {
        console.error('An error occurred while loading the model:', error);
      });    
        gltf.scene.traverse((child) => {
            if (child.isMesh) {
                // Ensure the material is opaque
                child.material.transparent = false;
                child.material.opacity = 1.0;
        
                // Optional: Update render order if transparency issues persist
                child.renderOrder = 1;
        
                // Force materials to update
                child.material.needsUpdate = true;
            }
        });


      // Set up the renderer
      const renderer = new THREE.WebGLRenderer({
        alpha: true,
        preserveDrawingBuffer: false,
        canvas: canvas,
        context: gl
      });
      renderer.autoClear = false;

      // Create the camera
      const camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;

      // Start the WebXR session
      const session = await navigator.xr.requestSession("immersive-ar");
      session.updateRenderState({
        baseLayer: new XRWebGLLayer(session, gl)
      });

      // Set up reference space
      const referenceSpace = await session.requestReferenceSpace('local');

      // Clock for animations
      const clock = new THREE.Clock();

      // Render loop
      const onXRFrame = (time, frame) => {
        session.requestAnimationFrame(onXRFrame);

        // Bind framebuffer
        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);

        // Get device pose
        const pose = frame.getViewerPose(referenceSpace);
        if (pose) {
          const view = pose.views[0];
          const viewport = session.renderState.baseLayer.getViewport(view);
          renderer.setSize(viewport.width, viewport.height);

          // Update the camera matrices
          camera.matrix.fromArray(view.transform.matrix);
          camera.projectionMatrix.fromArray(view.projectionMatrix);
          camera.updateMatrixWorld(true);

          // Update animations
          if (mixer) {
            const delta = clock.getDelta();
            mixer.update(delta);
          }

          // Render the scene
          renderer.render(scene, camera);
        }
      };

      session.requestAnimationFrame(onXRFrame);
    } catch (e) {
      console.error("Failed to start AR session", e);
    }
  }
</script>
</body>
</html>
