<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>AR Test</title>

  <!-- three.js -->
  <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
</head>
<body>

<button onclick="activateXR()">Start WebXR AR</button>
<script>
  let compassHeading = 0; // Global variable to store the heading

  // Listen for device orientation changes
  window.addEventListener("deviceorientationabsolute", (event) => {
      if (event.alpha !== null) {
          compassHeading = THREE.MathUtils.degToRad(event.alpha); // Convert degrees to radians
      } else {
          console.warn("Device orientation not supported or not granted permission.");
      }
  });

  async function activateXR() {
    try {
      const canvas = document.createElement("canvas");
      document.body.appendChild(canvas);
      const gl = canvas.getContext("webgl", {xrCompatible: true});

      const scene = new THREE.Scene();

      // Add lighting to illuminate the models
      const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
      scene.add(ambientLight);

      const directionalLight = new THREE.DirectionalLight(0xffffff, 0.6);
      directionalLight.position.set(1, 1, 1).normalize();
      scene.add(directionalLight);

      // Load the GLTF model
      const loader = new THREE.GLTFLoader();
      const modelUrl1 = 'https://raw.githubusercontent.com/VINDICTAS/webxr-test/main/Base3.glb';
      
      let mixer; // Declare the mixer globally for animation handling
      loader.load(
        modelUrl1,
        (gltf) => {
          const model1 = gltf.scene;

          // Adjust the size and position of the model
          model1.scale.set(0.5, 0.5, 0.5);
          model1.position.set(0, -1.5, -2);
          scene.add(model1);

          // Fix material transparency issues
          gltf.scene.traverse((child) => {
            if (child.isMesh) {
              child.material.transparent = false;
              child.material.opacity = 1.0;
              child.renderOrder = 1;
              child.material.needsUpdate = true;
            }
          });

          // Check if the model has animations
          if (gltf.animations && gltf.animations.length > 0) {
            mixer = new THREE.AnimationMixer(model1);

            // Play the first animation
            const action = mixer.clipAction(gltf.animations[0]);
            action.loop = THREE.LoopRepeat;
            action.reset();
            action.play();

            // Update animations in render loop
            const clock = new THREE.Clock();
            const updateAnimations = () => {
              const delta = clock.getDelta();
              if (mixer) mixer.update(delta);
            };

            // Attach the update logic to the onXRFrame loop
            const originalOnXRFrame = onXRFrame;
            onXRFrame = (time, frame) => {
              updateAnimations();
              originalOnXRFrame(time, frame);
            };
          }
        },
        undefined,
        (error) => {
          console.error('An error occurred while loading the model:', error);
        }
      );

      // Set up the renderer
      const renderer = new THREE.WebGLRenderer({
        alpha: true,
        preserveDrawingBuffer: false,
        canvas: canvas,
        context: gl,
      });
      renderer.autoClear = false;

      // Create the camera
      const camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;

      // Start the WebXR session
      const session = await navigator.xr.requestSession("immersive-ar");
      session.updateRenderState({
        baseLayer: new XRWebGLLayer(session, gl),
      });

      // Set up reference space
      const referenceSpace = await session.requestReferenceSpace('local');

      // Render loop
      let onXRFrame = (time, frame) => {
        session.requestAnimationFrame(onXRFrame);

        // Bind framebuffer
        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);

        // Get device pose
        const pose = frame.getViewerPose(referenceSpace);
        if (pose) {
          const view = pose.views[0];
          const viewport = session.renderState.baseLayer.getViewport(view);
          renderer.setSize(viewport.width, viewport.height);

          // Update the camera matrices
          camera.matrix.fromArray(view.transform.matrix);
          camera.projectionMatrix.fromArray(view.projectionMatrix);
          camera.updateMatrixWorld(true);

          // Render the scene
          renderer.render(scene, camera);
        }
      };

      session.requestAnimationFrame(onXRFrame);
    } catch (e) {
      console.error("Failed to start AR session", e);
    }
  }
</script>
</body>
</html>
