<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>AR Test</title>

  <!-- three.js -->
  <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
</head>
<body>

<button onclick="activateXR()">Start WebXR AR</button>
<script>
async function activateXR() {
  try {
    const canvas = document.createElement("canvas");
    document.body.appendChild(canvas);
    const gl = canvas.getContext("webgl", {xrCompatible: true});

    const scene = new THREE.Scene();

    // Add lighting to illuminate the models
    const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
    scene.add(ambientLight);

    const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5);
    directionalLight.position.set(1, 1, 1).normalize();
    scene.add(directionalLight);

    // Load the first GLTF model
    const loader = new THREE.GLTFLoader();
    const modelUrl1 = 'https://raw.githubusercontent.com/VINDICTAS/webxr-test/main/Base2.glb';
    loader.load(modelUrl1, (gltf) => {
      const model1 = gltf.scene;

      // Adjust the size and position of the first model
      model1.scale.set(0.4, 0.4, 0.4);
      model1.position.set(0, -1, -10);  // Position the model

      // Add the first model to the scene
      scene.add(model1);

      // Check if the model has animations
      if (gltf.animations && gltf.animations.length > 0) {
        // Create an AnimationMixer to play animations
        const mixer = new THREE.AnimationMixer(model1);

        // Play the first animation (or choose a specific one)
        const action = mixer.clipAction(gltf.animations[0]);
        action.play();

        // Update the mixer on every frame
        const clock = new THREE.Clock();

        function updateMixer() {
          const delta = clock.getDelta();
          mixer.update(delta);
        }

        // Add the mixer update to the render loop
        const originalOnXRFrame = onXRFrame; // Preserve the original onXRFrame function
        const newOnXRFrame = (time, frame) => {
          updateMixer(); // Update animations
          originalOnXRFrame(time, frame); // Call the original onXRFrame
        };
        onXRFrame = newOnXRFrame; // Replace the onXRFrame function
      }
    }, undefined, (error) => {
      console.error('An error occurred while loading the first model:', error);
    });

    // Set up the renderer
    const renderer = new THREE.WebGLRenderer({
      alpha: true,
      preserveDrawingBuffer: false,
      canvas: canvas,
      context: gl
    });
    renderer.autoClear = false;

    // Create the camera
    const camera = new THREE.PerspectiveCamera();
    camera.matrixAutoUpdate = false;

    // Start the WebXR session
    const session = await navigator.xr.requestSession("immersive-ar");
    session.updateRenderState({
      baseLayer: new XRWebGLLayer(session, gl)
    });

    // Set up reference space
    const referenceSpace = await session.requestReferenceSpace('local');

    // Render loop
    let onXRFrame = (time, frame) => {
      session.requestAnimationFrame(onXRFrame);

      // Bind framebuffer
      gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);

      // Get device pose
      const pose = frame.getViewerPose(referenceSpace);
      if (pose) {
        const view = pose.views[0];
        const viewport = session.renderState.baseLayer.getViewport(view);
        renderer.setSize(viewport.width, viewport.height);

        // Update the camera matrices
        camera.matrix.fromArray(view.transform.matrix);
        camera.projectionMatrix.fromArray(view.projectionMatrix);
        camera.updateMatrixWorld(true);

        // Render the scene
        renderer.render(scene, camera);
      }
    };
    session.requestAnimationFrame(onXRFrame);
  } catch (e) {
    console.error("Failed to start AR session", e);
  }
}
</script>
</body>
</html>
